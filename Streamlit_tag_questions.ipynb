{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farouk96/Predict_tags_question/blob/main/Streamlit_tag_questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvFu5Bb_4Jq2",
        "outputId": "b023f99e-e578-481e-acef-fadc0daf9629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.2 MB 25.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 56.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 55.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 52.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 126 kB 42.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 791 kB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 374 kB 73.0 MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.24 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.6.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.30.1 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-NQHIEYLMaj",
        "outputId": "598ed769-1863-416d-d25e-5d5350f6ad78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app_tag.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app_tag.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# preprocessing functions\n",
        "def clean_text(text):\n",
        "      text = text.lower()\n",
        "      text = re.sub(r\"what's\", \"what is \", text)\n",
        "      text = re.sub(r\"\\'s\", \" \", text)\n",
        "      text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "      text = re.sub(r\"can't\", \"can not \", text)\n",
        "      text = re.sub(r\"n't\", \" not \", text)\n",
        "      text = re.sub(r\"i'm\", \"i am \", text)\n",
        "      text = re.sub(r\"\\'re\", \" are \", text)\n",
        "      text = re.sub(r\"\\'d\", \" would \", text)\n",
        "      text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "      text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "      text = re.sub(r\"\\'\\n\", \" \", text)\n",
        "      text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
        "      text = re.sub('\\s+', ' ', text)\n",
        "      text= re.sub('nan',' ',text)\n",
        "      text= re.sub('null',' ',text)\n",
        "      text= re.sub('func',' ',text)\n",
        "      text= re.sub(r'[0-9]', ' ', text) # remove numbers\n",
        "      #text= re.sub(r'(?:^| )\\w(?:$| )', ' ', text)\n",
        "      text = text.strip(' ')\n",
        "      return text\n",
        "\n",
        "token=ToktokTokenizer()\n",
        "punct = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "tags_features=['<python',\n",
        " '<javascript',\n",
        " '<java',\n",
        " '<reactjs',\n",
        " '<html',\n",
        " '<r',\n",
        " '<c#',\n",
        " '<android',\n",
        " '<python-3.x',\n",
        " '<pandas',\n",
        " '<node.js',\n",
        " '<sql',\n",
        " '<php',\n",
        " '<css',\n",
        " '<c++',\n",
        " '<flutter',\n",
        " '<arrays',\n",
        " '<c',\n",
        " '<django',\n",
        " '<angular',\n",
        " '<mysql',\n",
        " '<dataframe',\n",
        " '<typescript',\n",
        " '<jquery',\n",
        " '<swift',\n",
        " '<json',\n",
        " '<laravel',\n",
        " '<vue.js',\n",
        " '<ios',\n",
        " '<firebase',\n",
        " '<amazon-web-services',\n",
        " '<react-native',\n",
        " '<dart',\n",
        " '<postgresql',\n",
        " '<kotlin',\n",
        " '<azure',\n",
        " '<excel',\n",
        " '<numpy',\n",
        " '<spring-boot',\n",
        " '<sql-server',\n",
        " '<list',\n",
        " '<mongodb',\n",
        " '<docker',\n",
        " '<tensorflow',\n",
        " '<regex',\n",
        " '<spring',\n",
        " '<api',\n",
        " '<asp.net-core',\n",
        " '<oracle',\n",
        " '<vba',\n",
        " '<linux',\n",
        " '<string',\n",
        " '<swiftui',\n",
        " '<android-studio',\n",
        " '<loops',\n",
        " '<git',\n",
        " '<matplotlib',\n",
        " '<express',\n",
        " '<powershell',\n",
        " '<bash',\n",
        " '<selenium',\n",
        " '<wordpress',\n",
        " '<kubernetes',\n",
        " '<.net',\n",
        " '<ggplot2',\n",
        " '<database',\n",
        " '<algorithm',\n",
        " '<ruby-on-rails',\n",
        " '<function',\n",
        "'<apache-spark',\n",
        " '<keras',\n",
        " '<web-scraping',\n",
        " '<dictionary',\n",
        " '<google-cloud-firestore',\n",
        " '<ruby',\n",
        " '<visual-studio-code',\n",
        " '<machine-learning',\n",
        " '<discord',\n",
        " '<pyspark',\n",
        " '<csv',\n",
        " '<visual-studio',\n",
        " '<ajax',\n",
        " '<for-loop',\n",
        " '<azure-devops',\n",
        " '<xcode',\n",
        " '<google-sheets',\n",
        " '<tkinter',\n",
        " '<macos',\n",
        " '<scala',\n",
        " '<if-statement',\n",
        " '<.net-core',\n",
        " '<react-hooks',\n",
        " '<windows',\n",
        " '<xml',\n",
        " '<elasticsearch',\n",
        " '<dplyr',\n",
        " '<discord.py',\n",
        " '<mongoose',\n",
        " '<bootstrap-4',\n",
        " '<opencv']\n",
        "def strip_list_noempty(mylist):\n",
        "    newlist = (item.strip() if hasattr(item, 'strip') else item for item in mylist)\n",
        "    return [item for item in newlist if item != '']\n",
        "def clean_punct(text): \n",
        "    words=token.tokenize(text)\n",
        "    punctuation_filtered = []\n",
        "    regex = re.compile('[%s]' % re.escape(punct))\n",
        "    remove_punctuation = str.maketrans(' ', ' ', punct)\n",
        "    for w in words:\n",
        "        if w in tags_features:\n",
        "            punctuation_filtered.append(w)\n",
        "        else:\n",
        "            punctuation_filtered.append(regex.sub('', w))\n",
        "  \n",
        "    filtered_list = strip_list_noempty(punctuation_filtered)\n",
        "        \n",
        "    return ' '.join(map(str, filtered_list))\n",
        "\n",
        "lemma=WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "def lemitizeWords(text):\n",
        "    words=token.tokenize(text)\n",
        "    listLemma=[]\n",
        "    for w in words:\n",
        "        x=lemma.lemmatize(w, pos=\"v\")\n",
        "        listLemma.append(x)\n",
        "    return ' '.join(map(str, listLemma))\n",
        "\n",
        "def stopWordsRemove(text):\n",
        "    \n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    \n",
        "    words=token.tokenize(text)\n",
        "    \n",
        "    filtered = [w for w in words if not w in stop_words]\n",
        "    \n",
        "    return ' '.join(map(str, filtered))\n",
        "####################################################################\n",
        "st.title('Question_tags_suggestion')\n",
        "title = st.text_input('Le titre')\n",
        "qst= st.text_area('Posez votre question')\n",
        "\n",
        "if title=='':\n",
        "  st.write(\"Svp,ecrivez le titre.\")\n",
        "elif qst=='':\n",
        "  st.write(\"Svp,ecrivez la question.\")\n",
        "else:\n",
        "  #preprocessing a title & text\n",
        "  lst=[title,qst]\n",
        "  for j in lst:\n",
        "    j = str(j)\n",
        "    j = clean_text(j) \n",
        "    j = clean_punct(j) \n",
        "    j = lemitizeWords(j) \n",
        "    j = stopWordsRemove(j)\n",
        "  #Download a vectorizer   \n",
        "  with open('/content/drive/MyDrive/ P5_HADJ NACER_Farouk/Vectorizer question1','rb') as S:\n",
        "    vectorizer1=pickle.load(S)\n",
        "  with open('/content/drive/MyDrive/ P5_HADJ NACER_Farouk/Vectorizer question2','rb') as T:\n",
        "    vectorizer2=pickle.load(T)   \n",
        "  title=[title]\n",
        "  qst=[qst]\n",
        "  title= vectorizer2.transform(title) \n",
        "  qst= vectorizer1.transform(qst)\n",
        "  X= hstack([qst,title])\n",
        "\n",
        "  #Download a best model\n",
        "  with open('/content/drive/MyDrive/ P5_HADJ NACER_Farouk/Best tager questions','rb') as f:\n",
        "    model =pickle.load(f)\n",
        "  st.subheader('Tags:')\n",
        "  #Download a multi_label\n",
        "  with open('/content/drive/MyDrive/ P5_HADJ NACER_Farouk/Multi_label','rb') as H:\n",
        "    multi_label =pickle.load(H)\n",
        "  pred =list(model.predict(X))\n",
        "  R= 159-len(pred)\n",
        "  for i in range(R):\n",
        "    pred.append(0)\n",
        "  pred= np.array(pred)\n",
        "  #pred.reshape(pred.shape[1],1)\n",
        "  st.write(multi_label.inverse_transform(pred))\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHl5CLTyON4H",
        "outputId": "d84d88ea-2518-40c0-a35d-24d4e983e997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.907s\n",
            "your url is: https://unlucky-eagle-43.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.85.226.42:8501\u001b[0m\n",
            "\u001b[0m\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/content/app_tag.py:221: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  pred= np.array(pred)\n",
            "2021-12-22 10:24:58.292 Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/streamlit/script_runner.py\", line 354, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app_tag.py\", line 223, in <module>\n",
            "    st.write(multi_label.inverse_transform(pred))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\", line 900, in inverse_transform\n",
            "    if yt.shape[1] != len(self.classes_):\n",
            "IndexError: tuple index out of range\n",
            "\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app_tag.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTpu3vx5oRzM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "ch=[]\n",
        "for i in range(40):\n",
        "  ch.append(1)\n",
        "R=100-len(ch)-1\n",
        "for i in range(R):\n",
        "  ch.append(0)\n",
        "ch=np.array([ch])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deZiFKT1xoaw",
        "outputId": "23bb07d2-1162-4530-af32-002b53d50053"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "JF_qtmCXpSYa",
        "outputId": "9327fb29-e2b2-4723-f6ab-057855d6aca8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-0a4d893c8860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ P5_HADJ NACER_Farouk/Multi_label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmulti_label\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmulti_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, yt)\u001b[0m\n\u001b[1;32m    901\u001b[0m             raise ValueError(\n\u001b[1;32m    902\u001b[0m                 \"Expected indicator for {0} classes, but got {1}\".format(\n\u001b[0;32m--> 903\u001b[0;31m                     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 )\n\u001b[1;32m    905\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected indicator for 100 classes, but got 99"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/ P5_HADJ NACER_Farouk/Multi_label','rb') as H:\n",
        "    multi_label =pickle.load(H)\n",
        "multi_label.inverse_transform(ch)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Streamlit tag questions.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "10F8aqJFV-rTwgFzqCnWwEq6jza_UIzMw",
      "authorship_tag": "ABX9TyP7I3Tltxx3hhN/zj3dxNKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}